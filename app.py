import streamlit as st
import sqlite3
import openai
import os
from dotenv import load_dotenv
from contextlib import contextmanager
from difflib import SequenceMatcher

# ë² íƒ€ í…ŒìŠ¤íŠ¸ ì„¤ì •
BETA_TEST = True  # ë² íƒ€ í…ŒìŠ¤íŠ¸ê°€ ëë‚˜ë©´ Falseë¡œ ë³€ê²½

# Streamlit configuration
st.set_page_config(
    page_title="ì˜ë£Œ ìƒë‹´ ì±—ë´‡",
    page_icon="ğŸ¥",
    layout="wide"
)

# Server configuration
if __name__ == "__main__":
    import sys
    sys.argv = ["streamlit", "run", __file__, "--server.address", "0.0.0.0", "--server.port", "8504"]

# Load environment variables
load_dotenv()

# Get API key from environment variable
openai.api_key = os.getenv("OPENAI_API_KEY")
if not openai.api_key:
    st.error("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# Database context manager
@contextmanager
def get_db_connection():
    conn = sqlite3.connect("qa.db")
    try:
        yield conn
    finally:
        conn.close()

# â–¶ï¸ SQLite ì´ˆê¸°í™”
def init_db():
    with get_db_connection() as conn:
        c = conn.cursor()
        c.execute('''
            CREATE TABLE IF NOT EXISTS qa_dataset (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                question TEXT NOT NULL,
                answer TEXT NOT NULL,
                source TEXT NOT NULL,
                approved BOOLEAN DEFAULT FALSE,
                tags TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        conn.commit()

# â–¶ï¸ ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜
def similar(a, b):
    # ë¬¸ì¥ì„ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ì—¬ ë¹„êµ
    a_words = set(a.split())
    b_words = set(b.split())
    
    # ê³µí†µ ë‹¨ì–´ ìˆ˜ ê³„ì‚°
    common_words = a_words.intersection(b_words)
    
    # ì „ì²´ ë‹¨ì–´ ìˆ˜
    total_words = len(a_words.union(b_words))
    
    # ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)
    if total_words == 0:
        return 0.0
    return len(common_words) / total_words

# â–¶ï¸ ìœ ì‚¬í•œ ì§ˆë¬¸ ì°¾ê¸°
def find_similar_question(question, threshold=0.8):  # ì„ê³„ê°’ì„ 0.8ë¡œ ë†’ì„
    with get_db_connection() as conn:
        c = conn.cursor()
        c.execute("SELECT question, answer FROM qa_dataset")
        saved_qa = c.fetchall()
        
        for saved_q, saved_a in saved_qa:
            if similar(question, saved_q) > threshold:
                return saved_q, saved_a
    return None, None

# â–¶ï¸ GPT ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def gpt_answer(question):
    try:
        # ë¨¼ì € ìœ ì‚¬í•œ ì§ˆë¬¸ì´ ìˆëŠ”ì§€ í™•ì¸
        similar_q, similar_a = find_similar_question(question)
        if similar_q:
            return similar_a  # ë‹µë³€ë§Œ ë°˜í™˜
        
        response = openai.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì˜ë£Œ ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì •í™•í•˜ê³  ì „ë¬¸ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”. ëª¨ë“  ë‹µë³€ì€ í•œê¸€ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."},
                {"role": "user", "content": question}
            ],
            temperature=0.7,
            max_tokens=1000
        )
        return response['choices'][0]['message']['content']
    except Exception as e:
        st.error(f"GPT ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None

# â–¶ï¸ ì‘ë‹µ ì €ì¥ í•¨ìˆ˜
def save_answer(question, answer, approved=True):
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("""
                INSERT INTO qa_dataset (question, answer, source, approved) 
                VALUES (?, ?, ?, ?)
            """, (question, answer, "GPT-4", approved))
            conn.commit()
            return True
    except Exception as e:
        st.error(f"ì‘ë‹µ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return False

# â–¶ï¸ ì €ì¥ëœ ë°ì´í„° ë³´ê¸° í•¨ìˆ˜
def view_saved_data():
    with get_db_connection() as conn:
        c = conn.cursor()
        c.execute("SELECT question, answer, created_at FROM qa_dataset ORDER BY created_at DESC")
        saved_data = c.fetchall()
        return saved_data

# â–¶ï¸ ì•± ì‹œì‘
init_db()
st.title("ì˜ë£Œ ìƒë‹´ ì±—ë´‡ ë² íƒ€ í…ŒìŠ¤íŠ¸")


# íƒ­ ìƒì„± (ë² íƒ€ í…ŒìŠ¤íŠ¸ ì¤‘ì¼ ë•Œë§Œ ì €ì¥ëœ ìƒë‹´ ë³´ê¸° íƒ­ í‘œì‹œ)
if BETA_TEST:
    tab1, tab2 = st.tabs(["ìƒë‹´í•˜ê¸°", "ì €ì¥ëœ ìƒë‹´ ë³´ê¸°"])
else:
    tab1 = st.container()

with tab1:
    # Session state ì´ˆê¸°í™”
    if 'last_question' not in st.session_state:
        st.session_state.last_question = ''

    # ì‚¬ìš©ì ì…ë ¥ì´ ë³€ê²½ë  ë•Œ í˜¸ì¶œë˜ëŠ” í•¨ìˆ˜
    def on_input_change():
        current_question = st.session_state.question
        if current_question and current_question != st.session_state.last_question:
            st.session_state.last_question = current_question
            with st.spinner("ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                answer = gpt_answer(current_question)
                if answer:
                    st.session_state.current_answer = answer

    # ì‚¬ìš©ì ì…ë ¥
    question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  Enter í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”:", key="question", on_change=on_input_change)

    # ì‘ë‹µ í‘œì‹œ
    if 'current_answer' in st.session_state:
        st.markdown("#### GPT ì‘ë‹µ")
        st.write(st.session_state.current_answer)
        
        # ì €ì¥ ì˜µì…˜
        if st.button("ì´ ì‘ë‹µ ì €ì¥í•˜ê¸°"):
            if save_answer(question, st.session_state.current_answer):
                st.success("ì‘ë‹µì´ qa.dbì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if BETA_TEST:
    with tab2:
        st.markdown("### ì €ì¥ëœ ìƒë‹´ ë‚´ì—­")
        saved_data = view_saved_data()
        if saved_data:
            for q, a, date in saved_data:
                with st.expander(f"ì§ˆë¬¸: {q} ({date})"):
                    st.write(f"ë‹µë³€: {a}")
        else:
            st.info("ì•„ì§ ì €ì¥ëœ ìƒë‹´ ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
